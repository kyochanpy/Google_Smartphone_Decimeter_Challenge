{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled126.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "CnELqZfmOwbr",
        "N-kSEd_epofF",
        "1a-6kKK2OwW1"
      ],
      "mount_file_id": "1lXtX3b8oZbCrBJ2x8Niek9ejvNZUlDMn",
      "authorship_tag": "ABX9TyNiATW3cjt2ZVIXldhGPHxR",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "0439c0b364f9464cab02ae9491ef582a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_d594c5d2c492424894f80898bd6df2aa",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_52965c1753c14e98b365788af7e0fa6a",
              "IPY_MODEL_bb5c485d2ca94021bed3cd62747424ed"
            ]
          }
        },
        "d594c5d2c492424894f80898bd6df2aa": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "52965c1753c14e98b365788af7e0fa6a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_d32d7f326c18456c96fe5bcc8435c280",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 73,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 73,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_12e8b6d1f0254d50b82b17514f1ed468"
          }
        },
        "bb5c485d2ca94021bed3cd62747424ed": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_83a50f7026394224936d20f5fdced67f",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 73/73 [00:55&lt;00:00,  1.32it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_d3769aefdfd042c2988d1cb4685e6218"
          }
        },
        "d32d7f326c18456c96fe5bcc8435c280": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "12e8b6d1f0254d50b82b17514f1ed468": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "83a50f7026394224936d20f5fdced67f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "d3769aefdfd042c2988d1cb4685e6218": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "01bf756b3a74465f929b08a2efc96cb3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_17974162bf38469f9628811e8e27414e",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_f5728f1783324a3b9f11d891596842f6",
              "IPY_MODEL_f01432b1a746489e966dadeae5743798"
            ]
          }
        },
        "17974162bf38469f9628811e8e27414e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "f5728f1783324a3b9f11d891596842f6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_6141c6e56b704b058312167647d41148",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 48,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 48,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_2a50a1ffe6c34aa190eebd7de6aa4075"
          }
        },
        "f01432b1a746489e966dadeae5743798": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_41e1d0df8a3e4916b48fba5065874b51",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 48/48 [00:34&lt;00:00,  1.39it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_b70f60875963407db81116ad407da7e7"
          }
        },
        "6141c6e56b704b058312167647d41148": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "2a50a1ffe6c34aa190eebd7de6aa4075": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "41e1d0df8a3e4916b48fba5065874b51": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "b70f60875963407db81116ad407da7e7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kyochanpy/Google_Smartphone_Decimeter_Challenge/blob/main/note_book/submission_61.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IicojqA4RFQF"
      },
      "source": [
        "#ライブラリ"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z85pRKVLfKjg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dcf08e29-ba55-4823-e16e-eb6e5b17baf6"
      },
      "source": [
        "!pip install optuna > /dev/null\n",
        "!pip install pyproj > /dev/null\n",
        "!pip install simdkalman > /dev/null\n",
        "!pip install osmnx momepy geopandas > /dev/null\n",
        "    \n",
        "import os\n",
        "from glob import glob\n",
        "from pathlib import Path\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import math\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib_venn import venn2, venn2_circles\n",
        "import seaborn as sns\n",
        "from scipy.ndimage import gaussian_filter1d\n",
        "from scipy.interpolate import interp1d\n",
        "\n",
        "from shapely.geometry import Point\n",
        "import osmnx as ox\n",
        "import momepy\n",
        "import geopandas as gpd\n",
        "import optuna\n",
        "import plotly\n",
        "import plotly.express as px\n",
        "import pyproj\n",
        "from pathlib import Path\n",
        "from pyproj import Proj, transform\n",
        "from tqdm.notebook import tqdm\n",
        "import simdkalman"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-colab 1.0.0 requires requests~=2.23.0, but you have requests 2.26.0 which is incompatible.\n",
            "datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\n",
            "albumentations 0.1.12 requires imgaug<0.2.7,>=0.2.5, but you have imgaug 0.2.9 which is incompatible.\u001b[0m\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/geopandas/_compat.py:110: UserWarning: The Shapely GEOS version (3.8.0-CAPI-1.13.1 ) is incompatible with the GEOS version PyGEOS was compiled with (3.9.1-CAPI-1.14.2). Conversions between both will be slow.\n",
            "  shapely_geos_version, geos_capi_version_string\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XjCkkklkRJWK"
      },
      "source": [
        "#Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gs18L1gdRLBS"
      },
      "source": [
        "dir = Path(\"/content/drive/MyDrive/GSDC\")\n",
        "train_base = pd.read_csv(dir / \"baseline_locations_train.csv\")\n",
        "\n",
        "#test_base = pd.read_csv(dir / \"baseline_locations_test.csv\")\n",
        "test_base = pd.read_csv(\"/content/drive/MyDrive/GSDC/test_predict_next_point_SJC_2.csv\")\n",
        "\n",
        "sub = pd.read_csv(dir / \"sample_submission.csv\")\n",
        "\n",
        "\n",
        "def get_groundtruth(path: Path) -> pd.DataFrame:\n",
        "        output_df = pd.DataFrame()\n",
        "        \n",
        "        for path in glob(str(dir / 'train/*/*/ground_truth.csv')):\n",
        "            _df = pd.read_csv(path)\n",
        "            output_df = pd.concat([output_df, _df])\n",
        "        output_df = output_df.reset_index(drop=True)\n",
        "        \n",
        "        _columns = ['latDeg', 'lngDeg', 'heightAboveWgs84EllipsoidM']\n",
        "        output_df[['t_'+col for col in _columns]] = output_df[_columns]\n",
        "        output_df = output_df.drop(columns=_columns, axis=1)\n",
        "        return output_df\n",
        "\n",
        "train_base = train_base.merge(\n",
        "    get_groundtruth(dir),\n",
        "    on=['collectionName', 'phoneName', 'millisSinceGpsEpoch']\n",
        ")"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gbZuWd-A2Gpz"
      },
      "source": [
        "train_SJC_list = [\"2021-04-22-US-SJC-1\", \"2021-04-28-US-SJC-1\", \"2021-04-29-US-SJC-2\"]\n",
        "test_SJC_list = [\"2021-04-22-US-SJC-2\", \"2021-04-29-US-SJC-3\"]\n",
        "\n",
        "train_SJCs = []\n",
        "for SJC in train_SJC_list:\n",
        "    SJC_df = train_base[train_base[\"collectionName\"] == SJC]\n",
        "    train_SJCs.append(SJC_df)\n",
        "train_SJC = pd.concat(train_SJCs)\n",
        "\n",
        "test_SJCs = []\n",
        "for SJC in test_SJC_list:\n",
        "    SJC_df = test_base[test_base[\"collectionName\"] == SJC]\n",
        "    test_SJCs.append(SJC_df)\n",
        "test_SJC = pd.concat(test_SJCs)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8nYo9kLURLVk"
      },
      "source": [
        "#共通関数"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mW_WsQDmSEFA"
      },
      "source": [
        "def calc_haversine(lat1, lon1, lat2, lon2):\n",
        "    RADIUS = 6_367_000\n",
        "    lat1, lon1, lat2, lon2 = map(np.radians, [lat1, lon1, lat2, lon2])\n",
        "    dlat = lat2 - lat1\n",
        "    dlon = lon2 - lon1\n",
        "    d = np.sin(dlat/2)**2 + np.cos(lat1) * np.cos(lat2) * np.sin(dlon/2)**2\n",
        "    dist = 2 * RADIUS * np.arcsin(d**0.5)\n",
        "    return dist"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uzOBPU05Obwe"
      },
      "source": [
        "#defs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7VWL4s00VSz9"
      },
      "source": [
        "##mean points"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mzyn_Yr4VSjq"
      },
      "source": [
        "def add_mean_points_features(input_df):\n",
        "    output_df = input_df.copy()\n",
        "    length = len(output_df[\"phone\"].values)\n",
        "    output_df[\"latDeg_pro_1\"] = output_df[\"latDeg\"].shift(-1)\n",
        "    output_df[\"latDeg_pro_2\"] = output_df[\"latDeg\"].shift(-2)\n",
        "    output_df[\"lngDeg_pro_1\"] = output_df[\"lngDeg\"].shift(-1)\n",
        "    output_df[\"lngDeg_pro_2\"] = output_df[\"lngDeg\"].shift(-2)\n",
        "    output_df[\"millisSinceGpsEpoch_pro_1\"] = output_df[\"millisSinceGpsEpoch\"].shift(-1)\n",
        "    output_df[\"millisSinceGpsEpoch_pro_2\"] = output_df[\"millisSinceGpsEpoch\"].shift(-2)\n",
        "    output_df[\"latDeg_mean_point\"] = (output_df[\"latDeg\"] + ((output_df[\"latDeg_pro_2\"] - output_df[\"latDeg\"]) * \n",
        "                                                            ((output_df[\"millisSinceGpsEpoch_pro_1\"] - output_df[\"millisSinceGpsEpoch\"]) /\n",
        "                                                            (output_df[\"millisSinceGpsEpoch_pro_2\"] - output_df[\"millisSinceGpsEpoch\"])))).shift(1)\n",
        "        \n",
        "    output_df[\"lngDeg_mean_point\"] = (output_df[\"lngDeg\"] + ((output_df[\"lngDeg_pro_2\"] - output_df[\"lngDeg\"]) * \n",
        "                                                            ((output_df[\"millisSinceGpsEpoch_pro_1\"] - output_df[\"millisSinceGpsEpoch\"]) /\n",
        "                                                            (output_df[\"millisSinceGpsEpoch_pro_2\"] - output_df[\"millisSinceGpsEpoch\"])))).shift(1)\n",
        "\n",
        "    return output_df"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f3J2YfsFcBrx"
      },
      "source": [
        "def mean_points(input_df):\n",
        "    output_df = input_df.copy()\n",
        "\n",
        "    lat_list = []\n",
        "    lng_list = []\n",
        "\n",
        "    for collection in output_df[\"collectionName\"].unique():\n",
        "        collection_df = output_df[output_df[\"collectionName\"] == collection]\n",
        "        if collection in output_df[\"collectionName\"].unique():\n",
        "            for phone in collection_df[\"phoneName\"].unique():\n",
        "                phone_df = collection_df[collection_df[\"phoneName\"] == phone]\n",
        "                mean_points_df = add_mean_points_features(phone_df)\n",
        "                lat_head = mean_points_df[\"latDeg\"].values[0]\n",
        "                lng_head = mean_points_df[\"lngDeg\"].values[0]\n",
        "                lat_tail = mean_points_df[\"latDeg\"].values[-1]\n",
        "                lng_tail = mean_points_df[\"lngDeg\"].values[-1]\n",
        "                lat_tail_2 = mean_points_df[\"latDeg\"].values[-2]\n",
        "                lng_tail_2 = mean_points_df[\"lngDeg\"].values[-2]\n",
        "                for lat, lng, lat_1, lng_1, lat_2, lng_2, lat_mp, lng_mp in zip(\n",
        "                    mean_points_df[\"latDeg\"].to_numpy(),\n",
        "                    mean_points_df[\"lngDeg\"].to_numpy(),\n",
        "                    mean_points_df[\"latDeg_pro_1\"].to_numpy(),\n",
        "                    mean_points_df[\"lngDeg_pro_1\"].to_numpy(),\n",
        "                    mean_points_df[\"latDeg_pro_2\"].to_numpy(),\n",
        "                    mean_points_df[\"lngDeg_pro_2\"].to_numpy(),\n",
        "                    mean_points_df[\"latDeg_mean_point\"].to_numpy(),\n",
        "                    mean_points_df[\"lngDeg_mean_point\"].to_numpy()\n",
        "                ):\n",
        "                \n",
        "                        p0 = np.array([lat, lng])\n",
        "                        p1 = np.array([lat_1, lng_1])\n",
        "                        p2 = np.array([lat_2, lng_2])\n",
        "                        mp = np.array([lat_mp, lng_mp])\n",
        "\n",
        "                        vec_p0_p2 = (p2 - p0) / np.linalg.norm(p2 - p0)\n",
        "                        p0_mean_point = (p1 - p0) @ vec_p0_p2 * vec_p0_p2 + p0\n",
        "\n",
        "                        diff_p1_mp = mp - p0_mean_point\n",
        "\n",
        "                        lat_fixed = lat_1 + diff_p1_mp[0]\n",
        "                        lng_fixed = lng_1 + diff_p1_mp[1]\n",
        "\n",
        "                        if np.isnan(lat_fixed) == True:\n",
        "                            lat_list.append(lat)\n",
        "                            lng_list.append(lng)\n",
        "                            continue\n",
        "\n",
        "                        else:\n",
        "                            lat_list.append(lat_fixed)\n",
        "                            lng_list.append(lng_fixed)\n",
        "\n",
        "    output_df[\"latDeg\"] = lat_list\n",
        "    output_df[\"lngDeg\"] = lng_list\n",
        "    #output_df[\"latDeg\"] = output_df[\"latDeg\"].shift(1)\n",
        "    #output_df[\"lngDeg\"] = output_df[\"lngDeg\"].shift(1)\n",
        "    return output_df[input_df.columns]"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lb6v5CKEOeLA"
      },
      "source": [
        "## make triangle"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ws_ZaQeaSaIq"
      },
      "source": [
        "#必要な特徴量を追加\n",
        "def add_triangle_features(input_df):\n",
        "    output_df = input_df.copy()\n",
        "    output_df[\"latDeg_pro_1\"] = output_df[\"latDeg\"].shift(-1)\n",
        "    output_df[\"latDeg_pro_2\"] = output_df[\"latDeg\"].shift(-2)\n",
        "    output_df[\"lngDeg_pro_1\"] = output_df[\"lngDeg\"].shift(-1)\n",
        "    output_df[\"lngDeg_pro_2\"] = output_df[\"lngDeg\"].shift(-2)\n",
        "    output_df[\"millisSinceGpsEpoch_pro_1\"] = output_df[\"millisSinceGpsEpoch\"].shift(-1)\n",
        "    output_df[\"millisSinceGpsEpoch_pro_2\"] = output_df[\"millisSinceGpsEpoch\"].shift(-2)\n",
        "    output_df[\"latDeg_mean_point\"] = (output_df[\"latDeg\"] + ((output_df[\"latDeg_pro_2\"] - output_df[\"latDeg\"]) * \n",
        "                                                            ((output_df[\"millisSinceGpsEpoch_pro_1\"] - output_df[\"millisSinceGpsEpoch\"]) /\n",
        "                                                            (output_df[\"millisSinceGpsEpoch_pro_2\"] - output_df[\"millisSinceGpsEpoch\"])))).shift(1)\n",
        "        \n",
        "    output_df[\"lngDeg_mean_point\"] = (output_df[\"lngDeg\"] + ((output_df[\"lngDeg_pro_2\"] - output_df[\"lngDeg\"]) * \n",
        "                                                            ((output_df[\"millisSinceGpsEpoch_pro_1\"] - output_df[\"millisSinceGpsEpoch\"]) /\n",
        "                                                            (output_df[\"millisSinceGpsEpoch_pro_2\"] - output_df[\"millisSinceGpsEpoch\"])))).shift(1)\n",
        "\n",
        "\n",
        "    degree_list = []\n",
        "    for lat, lng, lat_1, lng_1, lat_2, lng_2 in zip(\n",
        "        output_df[\"latDeg\"].to_numpy(),\n",
        "        output_df[\"lngDeg\"].to_numpy(),\n",
        "        output_df[\"latDeg_pro_1\"].to_numpy(),\n",
        "        output_df[\"lngDeg_pro_1\"].to_numpy(),\n",
        "        output_df[\"latDeg_pro_2\"].to_numpy(),\n",
        "        output_df[\"lngDeg_pro_2\"].to_numpy()\n",
        "    ):\n",
        "        p0 = np.array([lat, lng])\n",
        "        p1 = np.array([lat_1, lng_1])\n",
        "        p2 = np.array([lat_2, lng_2])\n",
        "            \n",
        "        vec_p0 = p0 - p1\n",
        "        vec_p2 = p2 - p1\n",
        "        length_vec_p0 = np.linalg.norm(vec_p0)\n",
        "        length_vec_p2 = np.linalg.norm(vec_p2)\n",
        "        inner = np.inner(vec_p0, vec_p2)\n",
        "        degree = np.rad2deg(np.arccos(inner / (length_vec_p0 * length_vec_p2)))\n",
        "        degree_list.append(degree)\n",
        "    degree_list.insert(0, 180)\n",
        "    degree_list.pop(-1)\n",
        "    degree_list[-1] = 180\n",
        "    output_df[\"degree\"] = degree_list\n",
        "    return output_df"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yhw7N7ovQ37O"
      },
      "source": [
        "#主な処理\n",
        "def make_triangle(input_df):\n",
        "    output_df = input_df.copy()\n",
        "\n",
        "    lat_list = []\n",
        "    lng_list = []\n",
        "\n",
        "    for collection in output_df[\"collectionName\"].unique():\n",
        "        collection_df = output_df[output_df[\"collectionName\"] == collection]\n",
        "        if collection in output_df[\"collectionName\"].unique():\n",
        "            for phone in collection_df[\"phoneName\"].unique():\n",
        "                phone_df = collection_df[collection_df[\"phoneName\"] == phone]\n",
        "                triangle_df = add_triangle_features(phone_df)\n",
        "                for lat, lng, lat_mp, lng_mp, deg in zip(\n",
        "                    triangle_df[\"latDeg\"].to_numpy(),\n",
        "                    triangle_df[\"lngDeg\"].to_numpy(),\n",
        "                    triangle_df[\"latDeg_mean_point\"].to_numpy(),\n",
        "                    triangle_df[\"lngDeg_mean_point\"].to_numpy(),\n",
        "                    triangle_df[\"degree\"].to_numpy()\n",
        "                ):\n",
        "                    if deg < 155:\n",
        "                        lat_f = (lat + lat_mp)/2\n",
        "                        lng_f = (lng + lng_mp)/2\n",
        "                        lat_list.append(lat_f)\n",
        "                        lng_list.append(lng_f)\n",
        "                    else:\n",
        "                        lat_list.append(lat)\n",
        "                        lng_list.append(lng)\n",
        "        else:\n",
        "            for lat, lng in zip(\n",
        "                collection_df[\"latDeg\"].to_numpy(),\n",
        "                collection_df[\"lngDeg\"].to_numpy(),\n",
        "            ):\n",
        "                lat_list.append(lat)\n",
        "                lng_list.append(lng)\n",
        "    output_df[\"latDeg\"] = lat_list\n",
        "    output_df[\"lngDeg\"] = lng_list\n",
        "    return output_df[input_df.columns]"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CKPfyc7hOwk7"
      },
      "source": [
        "##outlier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8HxE9CslUEvz"
      },
      "source": [
        "def outlier_train(input_df):\n",
        "    output_df = input_df.copy()\n",
        "    output_df[\"phone\"] = output_df[\"collectionName\"] + \"_\" + output_df[\"phoneName\"]\n",
        "\n",
        "    output_df[\"dist_pre\"] = 0\n",
        "    output_df[\"dist_pro\"] = 0\n",
        "\n",
        "    output_df['latDeg_pre'] = output_df['latDeg'].shift(periods=1,fill_value=0)\n",
        "    output_df['lngDeg_pre'] = output_df['lngDeg'].shift(periods=1,fill_value=0)\n",
        "    output_df['latDeg_pro'] = output_df['latDeg'].shift(periods=-1,fill_value=0)\n",
        "    output_df['lngDeg_pro'] = output_df['lngDeg'].shift(periods=-1,fill_value=0)\n",
        "    output_df['dist_pre'] = calc_haversine(output_df.latDeg_pre, output_df.lngDeg_pre, output_df.latDeg, output_df.lngDeg)\n",
        "    output_df['dist_pro'] = calc_haversine(output_df.latDeg, output_df.lngDeg, output_df.latDeg_pro, output_df.lngDeg_pro)\n",
        "\n",
        "    list_phone = output_df['phone'].unique()\n",
        "    for phone in list_phone:\n",
        "        ind_s = output_df[train_base['phone'] == phone].index[0]\n",
        "        ind_e = output_df[train_base['phone'] == phone].index[-1]\n",
        "        output_df.loc[ind_s,'dist_pre'] = 0\n",
        "        output_df.loc[ind_e,'dist_pro'] = 0\n",
        "\n",
        "    pro_95 = output_df['dist_pro'].mean() + (output_df['dist_pro'].std() * 2)\n",
        "    pre_95 = output_df['dist_pre'].mean() + (output_df['dist_pre'].std() * 2)\n",
        "    ind = output_df[(output_df['dist_pro'] > pro_95)&(output_df['dist_pre'] > pre_95)][['dist_pre','dist_pro']].index\n",
        "\n",
        "    for i in ind:\n",
        "        output_df.loc[i,'latDeg'] = (output_df.loc[i-1,'latDeg'] + output_df.loc[i+1,'latDeg'])/2\n",
        "        output_df.loc[i,'lngDeg'] = (output_df.loc[i-1,'lngDeg'] + output_df.loc[i+1,'lngDeg'])/2\n",
        "\n",
        "    return output_df"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oTy8xbi5Uect"
      },
      "source": [
        "def outlier(input_df):\n",
        "    output_df = input_df\n",
        "\n",
        "    output_df[\"dist_pre\"] = 0\n",
        "    output_df[\"dist_pro\"] = 0\n",
        "\n",
        "    output_df['latDeg_pre'] = output_df['latDeg'].shift(periods=1,fill_value=0)\n",
        "    output_df['lngDeg_pre'] = output_df['lngDeg'].shift(periods=1,fill_value=0)\n",
        "    output_df['latDeg_pro'] = output_df['latDeg'].shift(periods=-1,fill_value=0)\n",
        "    output_df['lngDeg_pro'] = output_df['lngDeg'].shift(periods=-1,fill_value=0)\n",
        "    output_df['dist_pre'] = calc_haversine(output_df.latDeg_pre, output_df.lngDeg_pre, output_df.latDeg, output_df.lngDeg)\n",
        "    output_df['dist_pro'] = calc_haversine(output_df.latDeg, output_df.lngDeg, output_df.latDeg_pro, output_df.lngDeg_pro)\n",
        "\n",
        "    list_phone = output_df['phone'].unique()\n",
        "    for phone in list_phone:\n",
        "        ind_s = output_df[test_base['phone'] == phone].index[0]\n",
        "        ind_e = output_df[test_base['phone'] == phone].index[-1]\n",
        "        output_df.loc[ind_s,'dist_pre'] = 0\n",
        "        output_df.loc[ind_e,'dist_pro'] = 0\n",
        "\n",
        "    pro_95 = output_df['dist_pro'].mean() + (output_df['dist_pro'].std() * 2)\n",
        "    pre_95 = output_df['dist_pre'].mean() + (output_df['dist_pre'].std() * 2)\n",
        "    ind = output_df[(output_df['dist_pro'] > pro_95)&(output_df['dist_pre'] > pre_95)][['dist_pre','dist_pro']].index\n",
        "\n",
        "    for i in ind:\n",
        "        output_df.loc[i,'latDeg'] = (output_df.loc[i-1,'latDeg'] + output_df.loc[i+1,'latDeg'])/2\n",
        "        output_df.loc[i,'lngDeg'] = (output_df.loc[i-1,'lngDeg'] + output_df.loc[i+1,'lngDeg'])/2\n",
        "\n",
        "    output_df[\"phoneName\"] = input_df[\"phoneName\"]\n",
        "    output_df[\"collectionName\"] = input_df[\"collectionName\"]\n",
        "    output_df[\"millisSinceGpsEpoch\"] = input_df[\"millisSinceGpsEpoch\"]\n",
        "\n",
        "    return output_df"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yGPdVzBZOwgo"
      },
      "source": [
        "##phones mean "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yzdAQsfnTNyd"
      },
      "source": [
        "def add_distance_diff(df):\n",
        "    df['latDeg_pre'] = df['latDeg'].shift(1)\n",
        "    df['latDeg_pro'] = df['latDeg'].shift(-1)\n",
        "    df['lngDeg_pre'] = df['lngDeg'].shift(1)\n",
        "    df['lngDeg_pro'] = df['lngDeg'].shift(-1)\n",
        "    df['phone_pre'] = df['phone'].shift(1)\n",
        "    df['phone_pro'] = df['phone'].shift(-1)\n",
        "    \n",
        "    df['dist_pre'] = calc_haversine(df['latDeg'], df['lngDeg'], df['latDeg_pre'], df['lngDeg_pre'])\n",
        "    df['dist_pro'] = calc_haversine(df['latDeg'], df['lngDeg'], df['latDeg_pro'], df['lngDeg_pro'])\n",
        "        \n",
        "    df.loc[df['phone']!=df['phone_pre'], ['latDeg_pre', 'lngDeg_pre', 'dist_pre']] = np.nan\n",
        "    df.loc[df['phone']!=df['phone_pro'], ['latDeg_pro', 'lngDeg_pro', 'dist_pro']] = np.nan\n",
        "        \n",
        "    return df\n",
        "\n",
        "\n",
        "def make_lerp_data(input_df):\n",
        "    org_colus = input_df.columns\n",
        "\n",
        "    time_list = input_df[[\"collectionName\", \"millisSinceGpsEpoch\"]].drop_duplicates()\n",
        "    phone_list = input_df[[\"collectionName\", \"phoneName\"]].drop_duplicates()\n",
        "    tmp = time_list.merge(phone_list, on=\"collectionName\", how=\"outer\")\n",
        "\n",
        "    output_df = tmp.merge(input_df, on=[\"collectionName\", \"millisSinceGpsEpoch\", \"phoneName\"], how=\"left\")\n",
        "    output_df[\"phone\"] = output_df[\"collectionName\"] + \"_\" + output_df[\"phoneName\"]\n",
        "    output_df = output_df.sort_values([\"phone\", \"millisSinceGpsEpoch\"])\n",
        "\n",
        "    output_df[\"latDeg_pre\"] = output_df[\"latDeg\"].shift(1)\n",
        "    output_df[\"latDeg_pro\"] = output_df[\"latDeg\"].shift(-1)\n",
        "    output_df[\"lngDeg_pre\"] = output_df[\"lngDeg\"].shift(1)\n",
        "    output_df[\"lngDeg_pro\"] = output_df[\"lngDeg\"].shift(-1)\n",
        "    output_df[\"phone_pre\"] = output_df[\"phone\"].shift(1)\n",
        "    output_df[\"phone_pro\"] = output_df[\"phone\"].shift(-1)\n",
        "    output_df[\"millisSinceGpsEpoch_pre\"] = output_df[\"millisSinceGpsEpoch\"].shift(1)\n",
        "    output_df[\"millisSinceGpsEpoch_pro\"] = output_df[\"millisSinceGpsEpoch\"].shift(-1)\n",
        "\n",
        "    output_df = output_df[(output_df[\"latDeg\"].isnull())&(output_df[\"phone\"] == output_df[\"phone_pre\"])&\n",
        "                        (output_df[\"phone\"] == output_df[\"phone_pro\"])].copy()\n",
        "\n",
        "    #preとproの間を経過時間を考慮して算出\n",
        "    output_df[\"latDeg\"] = output_df[\"latDeg_pre\"] + ((output_df[\"latDeg_pro\"] - output_df[\"latDeg_pre\"]) * \n",
        "                                                    ((output_df[\"millisSinceGpsEpoch\"] - output_df[\"millisSinceGpsEpoch_pre\"]) /\n",
        "                                                    (output_df[\"millisSinceGpsEpoch_pro\"] - output_df[\"millisSinceGpsEpoch_pre\"])))\n",
        "    output_df[\"lngDeg\"] = output_df[\"lngDeg_pre\"] + ((output_df[\"lngDeg_pro\"] - output_df[\"lngDeg_pre\"]) * \n",
        "                                                    ((output_df[\"millisSinceGpsEpoch\"] - output_df[\"millisSinceGpsEpoch_pre\"]) /\n",
        "                                                    (output_df[\"millisSinceGpsEpoch_pro\"] - output_df[\"millisSinceGpsEpoch_pre\"])))\n",
        "        \n",
        "    output_df = output_df[~output_df['latDeg'].isnull()]\n",
        "\n",
        "    return output_df[org_colus]\n",
        "\n",
        "def calc_mean_pred(input_df, lerp_df):\n",
        "    input_df[\"phone\"] = input_df[\"collectionName\"] + \"_\" + input_df[\"phoneName\"]\n",
        "    add_lerp = pd.concat([input_df, lerp_df])\n",
        "    mean_pred_result = add_lerp.groupby([\"collectionName\", \"millisSinceGpsEpoch\"])[[\"latDeg\", \"lngDeg\"]].mean().reset_index()\n",
        "    output_df = input_df[[\"collectionName\", \"phoneName\", \"millisSinceGpsEpoch\"]].copy()\n",
        "    output_df = output_df.merge(mean_pred_result[[\"collectionName\", \"millisSinceGpsEpoch\", \"latDeg\", \"lngDeg\"]],\n",
        "                                    on=[\"collectionName\", \"millisSinceGpsEpoch\"], how=\"left\")\n",
        "    output_df[\"phone\"] = output_df[\"collectionName\"] + \"_\" + output_df[\"phoneName\"]\n",
        "    return output_df"
      ],
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "irXr1lPUQ34y"
      },
      "source": [
        "def mean_prediction_train(input_df):\n",
        "    input_df[\"phone\"] = input_df[\"collectionName\"] + \"_\" + input_df[\"phoneName\"]\n",
        "\n",
        "    input_df_ = add_distance_diff(input_df)\n",
        "    th = 43\n",
        "    input_df_.loc[((input_df_['dist_pre'] > th) & (input_df_['dist_pro'] > th)), ['latDeg', 'lngDeg']] = np.nan\n",
        "    \n",
        "    lerp = make_lerp_data(input_df_)\n",
        "    mean_pred  = calc_mean_pred(input_df_, lerp)\n",
        "\n",
        "    output_df = kalman_filter(mean_pred)\n",
        "    output_df[\"t_latDeg\"] = input_df[\"t_latDeg\"].values\n",
        "    output_df[\"t_lngDeg\"] = input_df[\"t_lngDeg\"].values\n",
        "    \n",
        "    return output_df"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GwOzGB9X_C64"
      },
      "source": [
        "def mean_prediction(input_df):\n",
        "    input_df_ = add_distance_diff(input_df)\n",
        "    th = 43\n",
        "    input_df_.loc[((input_df_['dist_pre'] > th) & (input_df_['dist_pro'] > th)), ['latDeg', 'lngDeg']] = np.nan\n",
        "\n",
        "    test_lerp = make_lerp_data(input_df_)\n",
        "    test_mean_pred  = calc_mean_pred(input_df_, test_lerp)\n",
        "\n",
        "    output_df = kalman_filter(test_mean_pred)    \n",
        "    \n",
        "    return output_df"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "96vx8HrPOweU"
      },
      "source": [
        "##remove device"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4ITFL1nHUTes"
      },
      "source": [
        "def get_removedevice(input_df: pd.DataFrame, divece: str) -> pd.DataFrame:\n",
        "    input_df['index'] = input_df.index\n",
        "    input_df = input_df.sort_values('millisSinceGpsEpoch')\n",
        "    input_df.index = input_df['millisSinceGpsEpoch'].values\n",
        "\n",
        "    output_df = pd.DataFrame() \n",
        "    for _, subdf in input_df.groupby('collectionName'):\n",
        "\n",
        "        phones = subdf['phoneName'].unique()\n",
        "\n",
        "        if (len(phones) == 1) or (not divece in phones):\n",
        "            output_df = pd.concat([output_df, subdf])\n",
        "            continue\n",
        "\n",
        "        origin_df = subdf.copy()\n",
        "            \n",
        "        _index = subdf['phoneName']==divece\n",
        "        subdf.loc[_index, 'latDeg'] = np.nan\n",
        "        subdf.loc[_index, 'lngDeg'] = np.nan\n",
        "        subdf = subdf.interpolate(method='index', limit_area='inside')\n",
        "\n",
        "        _index = subdf['latDeg'].isnull()\n",
        "        subdf.loc[_index, 'latDeg'] = origin_df.loc[_index, 'latDeg'].values\n",
        "        subdf.loc[_index, 'lngDeg'] = origin_df.loc[_index, 'lngDeg'].values\n",
        "\n",
        "        output_df = pd.concat([output_df, subdf])\n",
        "\n",
        "    output_df.index = output_df['index'].values\n",
        "    output_df = output_df.sort_index()\n",
        "\n",
        "    del output_df['index']\n",
        "        \n",
        "    return output_df"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vUPaYaY5UK_Y"
      },
      "source": [
        "#remove_device\n",
        "def remove_device(input_df):\n",
        "\n",
        "    output_df = get_removedevice(input_df, 'SamsungS20Ultra')\n",
        "\n",
        "    return output_df"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CnELqZfmOwbr"
      },
      "source": [
        "##position shift"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vp0zDy5YUnn8"
      },
      "source": [
        "def position_shift_train(input_df):\n",
        "    sub_cols = sub.columns\n",
        "\n",
        "    train_p_s = pd.read_csv(dir / \"baseline_locations_train.csv\")\n",
        "    train_b = train_p_s[sub_cols]\n",
        "    test_b = test_base[sub_cols]\n",
        "\n",
        "    msge = \"millisSinceGpsEpoch\"\n",
        "\n",
        "    testdir = dir / 'test'\n",
        "    traindir = dir / 'train'\n",
        "\n",
        "    g_t = pd.DataFrame()\n",
        "    for d in os.listdir(traindir):\n",
        "        for p in os.listdir(traindir/d):\n",
        "            g_t = g_t.append(pd.read_csv(traindir/d/p/'ground_truth.csv'))\n",
        "\n",
        "    g_t[\"phone\"] = g_t[\"collectionName\"] + \"_\" + g_t[\"phoneName\"]\n",
        "    g_t_sub_cols = g_t[sub_cols]\n",
        "\n",
        "    transformer = pyproj.Transformer.from_crs(\n",
        "        {\"proj\":'geocent', \"ellps\":'WGS84', \"datum\":'WGS84'},\n",
        "        {\"proj\":'latlong', \"ellps\":'WGS84', \"datum\":'WGS84'},)\n",
        "    \n",
        "    def compute_dist(fname_1, fname_2):\n",
        "        oof = fname_1\n",
        "        g_t = fname_2\n",
        "        df = oof.merge(g_t, on=[\"phone\", \"millisSinceGpsEpoch\"])\n",
        "        dist_oof = calc_haversine(df.latDeg_x, df.lngDeg_x, df.latDeg_y, df.lngDeg_y)\n",
        "        scores = pd.DataFrame({\"phone\":df.phone, \"dist\":dist_oof})\n",
        "        scores_grp = scores.groupby(\"phone\")\n",
        "        d_50 = scores_grp.quantile(.50).reset_index()\n",
        "        d_50.columns = [\"phone\", \"q_50\"]\n",
        "        d_95 = scores_grp.quantile(.95).reset_index()\n",
        "        d_95.columns = [\"phone\", \"q_95\"]\n",
        "        return (scores_grp.quantile(.50).mean() + scores_grp.quantile(.95).mean()) / 2, d_50.merge(d_95)\n",
        "\n",
        "\n",
        "    def WGS84_to_ECEF(lat, lng, alt):\n",
        "        rad_lat = lat * (np.pi / 180.0)\n",
        "        rad_lng = lng * (np.pi / 180.0)\n",
        "        a = 6378137.0\n",
        "        finv = 298.257223563\n",
        "        f = 1 / finv   \n",
        "        e2 = 1 - (1 - f) * (1 - f)    \n",
        "        N = a / np.sqrt(1 - e2 * np.sin(rad_lat) * np.sin(rad_lat))\n",
        "        x = (N + alt) * np.cos(rad_lat) * np.cos(rad_lng)\n",
        "        y = (N + alt) * np.cos(rad_lat) * np.sin(rad_lng)\n",
        "        z = (N * (1 - e2) + alt)        * np.sin(rad_lat)\n",
        "        return x, y, z    \n",
        "\n",
        "\n",
        "    def ECEF_to_WGS84(x, y, z):\n",
        "        lng, lat, alt = transformer.transform(x, y, z, radians=False)\n",
        "        return lng, lat, alt\n",
        "\n",
        "    \n",
        "    def position_shift_(input_df, a):\n",
        "        output_df = input_df.copy()\n",
        "        output_df[\"heightAboveWgs84EllipsoidM\"] = 63.5\n",
        "        output_df[\"x\"], output_df[\"y\"], output_df[\"z\"] = zip(\n",
        "            *output_df.apply(lambda x: WGS84_to_ECEF(x.latDeg, x.lngDeg, \n",
        "                                                    x.heightAboveWgs84EllipsoidM), \n",
        "                            axis=1)\n",
        "\n",
        "        )\n",
        "        output_df.sort_values([\"phone\", msge], inplace=True)\n",
        "        for fi in [\"x\", \"y\", \"z\"]:\n",
        "            output_df[[fi + \"_p\"]] = output_df[fi].shift().where(output_df[\"phone\"].eq(output_df[\"phone\"].shift()))\n",
        "            output_df[[fi + \"_diff\"]] = output_df[fi] - output_df[fi + \"_p\"]\n",
        "\n",
        "        output_df[[\"dist\"]] = np.sqrt(output_df[\"x_diff\"]**2 + output_df[\"y_diff\"]**2 + output_df[\"z_diff\"]**2)\n",
        "        for fi in [\"x\", \"y\", \"z\"]:\n",
        "            output_df[[fi + \"_new\"]] = output_df[fi + \"_p\"] + output_df[fi + \"_diff\"] * (1 - a/output_df[\"dist\"])\n",
        "        lng, lat, alt = ECEF_to_WGS84(output_df[\"x_new\"].values, output_df[\"y_new\"].values, output_df[\"z_new\"].values)\n",
        "\n",
        "        lat[np.isnan(lat)] = output_df.loc[np.isnan(lat), \"latDeg\"]\n",
        "        lng[np.isnan(lng)] = output_df.loc[np.isnan(lng), \"lngDeg\"]\n",
        "        output_df[\"latDeg\"] = lat\n",
        "        output_df[\"lngDeg\"] = lng\n",
        "\n",
        "        output_df.sort_values([\"phone\", msge], inplace=True)\n",
        "\n",
        "        return output_df[sub_cols]\n",
        "\n",
        "    \n",
        "    def objective(trial):\n",
        "        a = trial.suggest_uniform(\"a\", -1, 1)\n",
        "        score, scores = compute_dist(position_shift_(train_b, a), g_t)\n",
        "        return score\n",
        "\n",
        "    study = optuna.create_study()\n",
        "    study.optimize(objective, n_trials=30)\n",
        "\n",
        "    output_df = position_shift_(input_df, a=study.best_params[\"a\"])\n",
        "\n",
        "    output_df[\"phoneName\"] = input_df[\"phoneName\"]\n",
        "    output_df[\"collectionName\"] = input_df[\"collectionName\"]\n",
        "    output_df[\"millisSinceGpsEpoch\"] = input_df[\"millisSinceGpsEpoch\"]\n",
        "    output_df[\"t_latDeg\"] = input_df[\"t_latDeg\"]\n",
        "    output_df[\"t_lngDeg\"] = input_df[\"t_lngDeg\"]\n",
        "\n",
        "    return output_df"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dB5IrAVe_dLE"
      },
      "source": [
        "def position_shift(input_df):\n",
        "    sub_cols = sub.columns\n",
        "\n",
        "    train_p_s = pd.read_csv(dir / \"baseline_locations_train.csv\")\n",
        "    train_b = train_p_s[sub_cols]\n",
        "    test_b = test_base[sub_cols]\n",
        "\n",
        "    msge = \"millisSinceGpsEpoch\"\n",
        "\n",
        "    testdir = dir / 'test'\n",
        "    traindir = dir / 'train'\n",
        "\n",
        "    g_t = pd.DataFrame()\n",
        "    for d in os.listdir(traindir):\n",
        "        for p in os.listdir(traindir/d):\n",
        "            g_t = g_t.append(pd.read_csv(traindir/d/p/'ground_truth.csv'))\n",
        "\n",
        "    g_t[\"phone\"] = g_t[\"collectionName\"] + \"_\" + g_t[\"phoneName\"]\n",
        "    g_t_sub_cols = g_t[sub_cols]\n",
        "\n",
        "    transformer = pyproj.Transformer.from_crs(\n",
        "        {\"proj\":'geocent', \"ellps\":'WGS84', \"datum\":'WGS84'},\n",
        "        {\"proj\":'latlong', \"ellps\":'WGS84', \"datum\":'WGS84'},)\n",
        "    \n",
        "    def compute_dist(fname_1, fname_2):\n",
        "        oof = fname_1\n",
        "        g_t = fname_2\n",
        "        df = oof.merge(g_t, on=[\"phone\", \"millisSinceGpsEpoch\"])\n",
        "        dist_oof = calc_haversine(df.latDeg_x, df.lngDeg_x, df.latDeg_y, df.lngDeg_y)\n",
        "        scores = pd.DataFrame({\"phone\":df.phone, \"dist\":dist_oof})\n",
        "        scores_grp = scores.groupby(\"phone\")\n",
        "        d_50 = scores_grp.quantile(.50).reset_index()\n",
        "        d_50.columns = [\"phone\", \"q_50\"]\n",
        "        d_95 = scores_grp.quantile(.95).reset_index()\n",
        "        d_95.columns = [\"phone\", \"q_95\"]\n",
        "        return (scores_grp.quantile(.50).mean() + scores_grp.quantile(.95).mean()) / 2, d_50.merge(d_95)\n",
        "\n",
        "\n",
        "    def WGS84_to_ECEF(lat, lng, alt):\n",
        "        rad_lat = lat * (np.pi / 180.0)\n",
        "        rad_lng = lng * (np.pi / 180.0)\n",
        "        a = 6378137.0\n",
        "        finv = 298.257223563\n",
        "        f = 1 / finv   \n",
        "        e2 = 1 - (1 - f) * (1 - f)    \n",
        "        N = a / np.sqrt(1 - e2 * np.sin(rad_lat) * np.sin(rad_lat))\n",
        "        x = (N + alt) * np.cos(rad_lat) * np.cos(rad_lng)\n",
        "        y = (N + alt) * np.cos(rad_lat) * np.sin(rad_lng)\n",
        "        z = (N * (1 - e2) + alt)        * np.sin(rad_lat)\n",
        "        return x, y, z    \n",
        "\n",
        "\n",
        "    def ECEF_to_WGS84(x, y, z):\n",
        "        lng, lat, alt = transformer.transform(x, y, z, radians=False)\n",
        "        return lng, lat, alt\n",
        "\n",
        "    \n",
        "    def position_shift_(input_df, a):\n",
        "        output_df = input_df.copy()\n",
        "        output_df[\"heightAboveWgs84EllipsoidM\"] = 63.5\n",
        "        output_df[\"x\"], output_df[\"y\"], output_df[\"z\"] = zip(\n",
        "            *output_df.apply(lambda x: WGS84_to_ECEF(x.latDeg, x.lngDeg, \n",
        "                                                    x.heightAboveWgs84EllipsoidM), \n",
        "                            axis=1)\n",
        "\n",
        "        )\n",
        "        output_df.sort_values([\"phone\", msge], inplace=True)\n",
        "        for fi in [\"x\", \"y\", \"z\"]:\n",
        "            output_df[[fi + \"_p\"]] = output_df[fi].shift().where(output_df[\"phone\"].eq(output_df[\"phone\"].shift()))\n",
        "            output_df[[fi + \"_diff\"]] = output_df[fi] - output_df[fi + \"_p\"]\n",
        "\n",
        "        output_df[[\"dist\"]] = np.sqrt(output_df[\"x_diff\"]**2 + output_df[\"y_diff\"]**2 + output_df[\"z_diff\"]**2)\n",
        "        for fi in [\"x\", \"y\", \"z\"]:\n",
        "            output_df[[fi + \"_new\"]] = output_df[fi + \"_p\"] + output_df[fi + \"_diff\"] * (1 - a/output_df[\"dist\"])\n",
        "        lng, lat, alt = ECEF_to_WGS84(output_df[\"x_new\"].values, output_df[\"y_new\"].values, output_df[\"z_new\"].values)\n",
        "\n",
        "        lat[np.isnan(lat)] = output_df.loc[np.isnan(lat), \"latDeg\"]\n",
        "        lng[np.isnan(lng)] = output_df.loc[np.isnan(lng), \"lngDeg\"]\n",
        "        output_df[\"latDeg\"] = lat\n",
        "        output_df[\"lngDeg\"] = lng\n",
        "\n",
        "        output_df.sort_values([\"phone\", msge], inplace=True)\n",
        "\n",
        "        return output_df[sub_cols]\n",
        "\n",
        "    \n",
        "    def objective(trial):\n",
        "        a = trial.suggest_uniform(\"a\", -1, 1)\n",
        "        score, scores = compute_dist(position_shift_(train_b, a), g_t)\n",
        "        return score\n",
        "\n",
        "    study = optuna.create_study()\n",
        "    study.optimize(objective, n_trials=30)\n",
        "\n",
        "    output_df = position_shift_(input_df, a=study.best_params[\"a\"])\n",
        "\n",
        "    output_df[\"phoneName\"] = input_df[\"phoneName\"]\n",
        "    output_df[\"collectionName\"] = input_df[\"collectionName\"]\n",
        "    output_df[\"millisSinceGpsEpoch\"] = input_df[\"millisSinceGpsEpoch\"]\n",
        "\n",
        "    return output_df"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N-kSEd_epofF"
      },
      "source": [
        "##adaptive_gauss+phone_mean"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PyY66-Iuppbc"
      },
      "source": [
        "def apply_gauss_smoothing(df, params):\n",
        "    SZ_1 = params['sz_1']\n",
        "    SZ_2 = params['sz_2']\n",
        "    SZ_CRIT = params['sz_crit']    \n",
        "    \n",
        "    unique_paths = df[['collectionName', 'phoneName']].drop_duplicates().to_numpy()\n",
        "    for collection, phone in unique_paths:\n",
        "        cond = np.logical_and(df['collectionName'] == collection, df['phoneName'] == phone)\n",
        "        data = df[cond][['latDeg', 'lngDeg']].to_numpy()\n",
        "                \n",
        "        lat_g1 = gaussian_filter1d(data[:, 0], np.sqrt(SZ_1))\n",
        "        lon_g1 = gaussian_filter1d(data[:, 1], np.sqrt(SZ_1))\n",
        "        lat_g2 = gaussian_filter1d(data[:, 0], np.sqrt(SZ_2))\n",
        "        lon_g2 = gaussian_filter1d(data[:, 1], np.sqrt(SZ_2))\n",
        "\n",
        "        lat_dif = data[1:,0] - data[:-1,0]\n",
        "        lon_dif = data[1:,1] - data[:-1,1]\n",
        "\n",
        "        lat_crit = np.append(np.abs(gaussian_filter1d(lat_dif, np.sqrt(SZ_CRIT)) / (1e-9 + gaussian_filter1d(np.abs(lat_dif), np.sqrt(SZ_CRIT)))),[0])\n",
        "        lon_crit = np.append(np.abs(gaussian_filter1d(lon_dif, np.sqrt(SZ_CRIT)) / (1e-9 + gaussian_filter1d(np.abs(lon_dif), np.sqrt(SZ_CRIT)))),[0])           \n",
        "            \n",
        "        df.loc[cond, 'latDeg'] = lat_g1 * lat_crit + lat_g2 * (1.0 - lat_crit)\n",
        "        df.loc[cond, 'lngDeg'] = lon_g1 * lon_crit + lon_g2 * (1.0 - lon_crit)    \n",
        "                       \n",
        "    return df"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w4FRuxbyppYo"
      },
      "source": [
        "def mean_with_other_phones(df):\n",
        "    collections_list = df[['collectionName']].drop_duplicates().to_numpy()\n",
        "\n",
        "    for collection in collections_list:\n",
        "        phone_list = df[df['collectionName'].to_list() == collection][['phoneName']].drop_duplicates().to_numpy()\n",
        "\n",
        "        phone_data = {}\n",
        "        corrections = {}\n",
        "        for phone in phone_list:\n",
        "            cond = np.logical_and(df['collectionName'] == collection[0], df['phoneName'] == phone[0]).to_list()\n",
        "            phone_data[phone[0]] = df[cond][['millisSinceGpsEpoch', 'latDeg', 'lngDeg']].to_numpy()\n",
        "\n",
        "        for current in phone_data:\n",
        "            correction = np.ones(phone_data[current].shape, dtype=np.float)\n",
        "            correction[:,1:] = phone_data[current][:,1:]\n",
        "            \n",
        "            # Telephones data don't complitely match by time, so - interpolate.\n",
        "            for other in phone_data:\n",
        "                if other == current:\n",
        "                    continue\n",
        "\n",
        "                loc = interp1d(phone_data[other][:,0], \n",
        "                               phone_data[other][:,1:], \n",
        "                               axis=0, \n",
        "                               kind='linear', \n",
        "                               copy=False, \n",
        "                               bounds_error=None, \n",
        "                               fill_value='extrapolate', \n",
        "                               assume_sorted=True)\n",
        "                \n",
        "                start_idx = 0\n",
        "                stop_idx = 0\n",
        "                for idx, val in enumerate(phone_data[current][:,0]):\n",
        "                    if val < phone_data[other][0,0]:\n",
        "                        start_idx = idx\n",
        "                    if val < phone_data[other][-1,0]:\n",
        "                        stop_idx = idx\n",
        "\n",
        "                if stop_idx - start_idx > 0:\n",
        "                    correction[start_idx:stop_idx,0] += 1\n",
        "                    correction[start_idx:stop_idx,1:] += loc(phone_data[current][start_idx:stop_idx,0])                    \n",
        "\n",
        "            correction[:,1] /= correction[:,0]\n",
        "            correction[:,2] /= correction[:,0]\n",
        "            \n",
        "            corrections[current] = correction.copy()\n",
        "        \n",
        "        for phone in phone_list:\n",
        "            cond = np.logical_and(df['collectionName'] == collection[0], df['phoneName'] == phone[0]).to_list()\n",
        "            \n",
        "            df.loc[cond, ['latDeg', 'lngDeg']] = corrections[phone[0]][:,1:]            \n",
        "            \n",
        "    return df"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VkTeRkC1ppWI"
      },
      "source": [
        "def gauss_filter(input_df):\n",
        "    input_df_ = input_df.copy()\n",
        "    output_df = mean_with_other_phones(\n",
        "        apply_gauss_smoothing(input_df_, {'sz_1' : 0.85, 'sz_2' : 5.65, 'sz_crit' : 1.5})\n",
        "    )\n",
        "    return output_df"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XOJ-khTwOwZX"
      },
      "source": [
        "##kalman filter"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4zGR-BYMXLJN"
      },
      "source": [
        "def apply_kf_smoothing(input_df, kf_):\n",
        "    output_df = input_df.copy()\n",
        "    unique_paths = output_df[['collectionName', 'phoneName']].drop_duplicates().to_numpy()\n",
        "    for collection, phone in tqdm(unique_paths):\n",
        "        cond = np.logical_and(output_df['collectionName'] == collection, output_df['phoneName'] == phone)\n",
        "        data = output_df[cond][['latDeg', 'lngDeg']].to_numpy()\n",
        "        data = data.reshape(1, len(data), 2)\n",
        "        smoothed = kf_.smooth(data)\n",
        "        output_df.loc[cond, 'latDeg'] = smoothed.states.mean[0, :, 0]\n",
        "        output_df.loc[cond, 'lngDeg'] = smoothed.states.mean[0, :, 1]\n",
        "    return output_df\n"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M2swWoDqXIKt"
      },
      "source": [
        "def kalman_filter(input_df):\n",
        "    T = 1.0\n",
        "    state_transition = np.array([[1, 0, T, 0, 0.5 * T ** 2, 0], [0, 1, 0, T, 0, 0.5 * T ** 2], [0, 0, 1, 0, T, 0],\n",
        "                                [0, 0, 0, 1, 0, T], [0, 0, 0, 0, 1, 0], [0, 0, 0, 0, 0, 1]])\n",
        "    process_noise = np.diag([1e-5, 1e-5, 5e-6, 5e-6, 1e-6, 1e-6]) + np.ones((6, 6)) * 1e-9\n",
        "    observation_model = np.array([[1, 0, 0, 0, 0, 0], [0, 1, 0, 0, 0, 0]])\n",
        "    observation_noise = np.diag([3e-5, 3e-5]) + np.ones((2, 2)) * 1e-9\n",
        "\n",
        "    kf = simdkalman.KalmanFilter(\n",
        "            state_transition = state_transition,\n",
        "            process_noise = process_noise,\n",
        "            observation_model = observation_model,\n",
        "            observation_noise = observation_noise)\n",
        "    \n",
        "    output_df = apply_kf_smoothing(input_df, kf)\n",
        "\n",
        "    return output_df\n"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1a-6kKK2OwW1"
      },
      "source": [
        "##move closer center SJC"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MKcb5LGGXyBS"
      },
      "source": [
        "def nearest_point(x, y, points):\n",
        "    result = {}\n",
        "    if len(points) == 0:\n",
        "        return result\n",
        "    result[0] = points[0][0]\n",
        "    result[1] = points[0][1]\n",
        "    stdval = math.sqrt((points[0][0] - x) ** 2 + (points[0][1] - y) ** 2)\n",
        "    for point in points:\n",
        "        distance = math.sqrt((point[0] - x) ** 2 + (point[1] - y) ** 2)\n",
        "        if stdval > distance:\n",
        "            result[0] = point[0]\n",
        "            result[1] = point[1]\n",
        "            stdval = distance\n",
        "    return [result[0], result[1]]"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A88CjUQ2Y4E5"
      },
      "source": [
        "def create_dataset_center(input_df):\n",
        "    output_df = input_df.copy()\n",
        "    collection_list = output_df[\"collectionName\"].unique()\n",
        "\n",
        "    line_points_dfs = []\n",
        "    c = 1\n",
        "    for collection in collection_list:\n",
        "        print(f\"now : {c}/{len(collection_list)}\")\n",
        "        c += 1\n",
        "        print(collection)\n",
        "        target_df = output_df[output_df[\"collectionName\"] == collection].reset_index(drop=True)\n",
        "        target_df[\"geometry\"] = [Point(p) for p in target_df[[\"lngDeg\", \"latDeg\"]].to_numpy()]\n",
        "        target_gdf = gpd.GeoDataFrame(target_df, geometry=target_df[\"geometry\"])\n",
        "\n",
        "        offset = 0.1**5\n",
        "        bbox = target_gdf.bounds + [-(offset+0.01), -(offset+0.01), offset+0.01, offset+0.01]\n",
        "        east = bbox[\"minx\"].min()\n",
        "        west = bbox[\"maxx\"].max()\n",
        "        south = bbox[\"miny\"].min()\n",
        "        north = bbox[\"maxy\"].max()\n",
        "        G = ox.graph.graph_from_bbox(north, south, east, west, network_type='drive')\n",
        "\n",
        "        nodes, edges = momepy.nx_to_gdf(G)\n",
        "        \n",
        "        edges = edges.dropna(subset=[\"geometry\"]).reset_index(drop=True)\n",
        "        hits = bbox.apply(lambda row: list(edges.sindex.intersection(row)), axis=1)\n",
        "        tmp = pd.DataFrame({\n",
        "            \"pt_idx\": np.repeat(hits.index, hits.apply(len)),\n",
        "            \"line_i\": np.concatenate(hits.values)\n",
        "        })\n",
        "        tmp = tmp.join(edges.reset_index(drop=True), on=\"line_i\")\n",
        "        tmp = tmp.join(target_gdf.geometry.rename(\"point\"), on=\"pt_idx\")\n",
        "        tmp = gpd.GeoDataFrame(tmp, geometry=\"geometry\", crs=target_gdf.crs)\n",
        "\n",
        "        tmp[\"snap_dist\"] = tmp.geometry.distance(gpd.GeoSeries(tmp.point))\n",
        "\n",
        "        tolerance = 0.0005  \n",
        "        tmp = tmp.loc[tmp.snap_dist <= tolerance]\n",
        "        tmp = tmp.sort_values(by=[\"snap_dist\"])\n",
        "\n",
        "        closest = tmp.groupby(\"pt_idx\").first()\n",
        "        closest = gpd.GeoDataFrame(closest, geometry=\"geometry\")\n",
        "        closest = closest.drop_duplicates(\"line_i\").reset_index(drop=True)\n",
        "\n",
        "        line_points_list = []\n",
        "        split = 200  # param: number of split in each LineString\n",
        "        for dist in range(0, split, 1):\n",
        "            dist = dist/split\n",
        "            line_points = closest[\"geometry\"].interpolate(dist, normalized=True)\n",
        "            line_points_list.append(line_points)\n",
        "        line_points = pd.concat(line_points_list).reset_index(drop=True)\n",
        "        line_points = line_points.reset_index().rename(columns={0:\"geometry\"})\n",
        "        line_points[\"lngDeg\"] = line_points[\"geometry\"].x\n",
        "        line_points[\"latDeg\"] = line_points[\"geometry\"].y\n",
        "        \n",
        "        line_points_ = line_points.loc[:, [\"lngDeg\", \"latDeg\"]]\n",
        "        line_points_dfs.append(line_points_)\n",
        "\n",
        "    line_points_df = pd.concat(line_points_dfs)\n",
        "    line_points_list = sorted(line_points_df.values.tolist())\n",
        "    \n",
        "    print(len(line_points_list))\n",
        "\n",
        "    nearest_point_list = []\n",
        "    \n",
        "    for lng, lat in zip(\n",
        "        output_df[\"lngDeg\"].to_numpy(),\n",
        "        output_df[\"latDeg\"].to_numpy()\n",
        "    ):\n",
        "        nearest_point_list.append(nearest_point(lng, lat, line_points_list))\n",
        "        \n",
        "    nearest_point_df = pd.DataFrame(nearest_point_list)\n",
        "    output_df[\"latDeg_center\"] = nearest_point_df[1].values\n",
        "    output_df[\"lngDeg_center\"] = nearest_point_df[0].values\n",
        "    \n",
        "    \n",
        "        \n",
        "    output_df[\"latDeg_center_pre\"] = output_df[\"latDeg_center\"].shift(1)\n",
        "    output_df[\"lngDeg_center_pre\"] = output_df[\"lngDeg_center\"].shift(1)\n",
        "\n",
        "    output_df['meter'] = output_df.apply(\n",
        "            lambda r: calc_haversine(\n",
        "                r.latDeg, r.lngDeg, r.latDeg_center, r.lngDeg_center\n",
        "            ),\n",
        "            axis=1\n",
        "        )\n",
        "    \n",
        "    rl_list = []\n",
        "    #for collection in output_df[\"collectionName\"].unique():\n",
        "        #for phone in output_df[\"phoneName\"].unique():\n",
        "            #phone_df = output_df[output_df[\"phone\"] == f\"{collection}_{phone}\"]\n",
        "    for lat, lng, lat_c, lng_c, lat_c_pre, lng_c_pre in zip(\n",
        "                output_df[\"latDeg\"].to_numpy(),\n",
        "                output_df[\"lngDeg\"].to_numpy(),\n",
        "                output_df[\"latDeg_center\"].to_numpy(),\n",
        "                output_df[\"lngDeg_center\"].to_numpy(),\n",
        "                output_df[\"latDeg_center_pre\"].to_numpy(),\n",
        "                output_df[\"lngDeg_center_pre\"].to_numpy()\n",
        "            ):\n",
        "                base_vec = np.array([lat-lat_c_pre, lng-lng_c_pre])\n",
        "                center_vec = np.array([lat_c-lat_c_pre, lng_c-lng_c_pre])\n",
        "                r_or_l = np.cross(base_vec,center_vec)\n",
        "                if r_or_l > 0:\n",
        "                    rl_list.append(\"Right\")\n",
        "                else:\n",
        "                    rl_list.append(\"Left\")\n",
        "    output_df[\"Right_or_left\"] = rl_list\n",
        "    \n",
        "    return output_df"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e_HYZMxfahpe"
      },
      "source": [
        "def check_meter_from_center(input_df):\n",
        "        output_df = input_df.copy()\n",
        "        lat_list = []\n",
        "        lng_list = []\n",
        "        for lat, lng, lat_c, lng_c, meter, rl in zip(\n",
        "            output_df[\"latDeg\"].to_numpy(),\n",
        "            output_df[\"lngDeg\"].to_numpy(),\n",
        "            output_df[\"latDeg_center\"].to_numpy(),\n",
        "            output_df[\"lngDeg_center\"].to_numpy(),\n",
        "            output_df[\"meter\"].to_numpy(),\n",
        "            output_df[\"Right_or_left\"].values\n",
        "        ):\n",
        "            if rl == \"Left\":\n",
        "                lat = lat_c\n",
        "                lng = lng_c\n",
        "                lat_list.append(lat)\n",
        "                lng_list.append(lng)\n",
        "            else:\n",
        "                if meter > 30:\n",
        "                    lat = lat\n",
        "                    lng = lng\n",
        "                elif meter > 10:\n",
        "                    lat = ((((lat + lat_c)/2 + lat_c)/2 + lat_c)/2 + lat_c)/2\n",
        "                    lng = ((((lng + lng_c)/2 + lng_c)/2 + lng_c)/2 + lng_c)/2\n",
        "                elif meter > 7.5:\n",
        "                    lat = (((lat + lat_c)/2 + lat_c)/2 + lat_c)/2\n",
        "                    lng = (((lng + lng_c)/2 + lng_c)/2 + lng_c)/2\n",
        "                elif meter > 5:\n",
        "                    lat = ((lat + lat_c)/2 + lat_c)/2\n",
        "                    lng = ((lng + lng_c)/2 + lng_c)/2\n",
        "                elif meter > 2.5:\n",
        "                    lat = (lat + lat_c)/2\n",
        "                    lng = (lng + lng_c)/2\n",
        "\n",
        "                lat_list.append(lat)\n",
        "                lng_list.append(lng)\n",
        "\n",
        "\n",
        "        output_df.iloc[:, 2] = lat_list\n",
        "        output_df.iloc[:, 3] = lng_list\n",
        "        return output_df"
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vyUAMkvTutKi"
      },
      "source": [
        "def move_closer_center_train(input_df):\n",
        "    train_SJC_list = [\"2021-04-22-US-SJC-1\", \"2021-04-28-US-SJC-1\", \"2021-04-29-US-SJC-2\"]\n",
        "    train_dfs = []\n",
        "    for collection in input_df[\"collectionName\"].unique():\n",
        "        if collection in train_SJC_list:\n",
        "            phones_dfs = []\n",
        "            collection_df = input_df[input_df[\"collectionName\"] == collection]\n",
        "            for phone in collection_df[\"phone\"].unique():\n",
        "                phone_df = collection_df[collection_df[\"phone\"] == phone]\n",
        "                phone_df = create_dataset_center(phone_df)\n",
        "                phone_df = check_meter_from_center(phone_df)\n",
        "                phones_dfs.append(phone_df)\n",
        "            collection_df = pd.concat(phones_dfs)\n",
        "            train_dfs.append(collection_df)\n",
        "        else:\n",
        "            train_dfs.append(input_df[input_df[\"collectionName\"] == collection])\n",
        "    output_df = pd.concat(train_dfs)\n",
        "\n",
        "    return output_df"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hCwntbSBjVO_"
      },
      "source": [
        "def move_closer_center(input_df):\n",
        "    test_SJC_list = [\"2021-04-22-US-SJC-2\", \"2021-04-29-US-SJC-3\"]\n",
        "    test_dfs = []\n",
        "    for collection in input_df[\"collectionName\"].unique():\n",
        "        if collection in test_SJC_list:\n",
        "            phones_dfs = []\n",
        "            collection_df = input_df[input_df[\"collectionName\"] == collection]\n",
        "            for phone in collection_df[\"phone\"].unique():\n",
        "                phone_df = collection_df[collection_df[\"phone\"] == phone]\n",
        "                phone_df = create_dataset_center(phone_df)\n",
        "                phone_df = check_meter_from_center(phone_df)\n",
        "                phones_dfs.append(phone_df)\n",
        "            collection_df = pd.concat(phones_dfs)\n",
        "            test_dfs.append(collection_df)\n",
        "        else:\n",
        "            test_dfs.append(input_df[input_df[\"collectionName\"] == collection])\n",
        "    output_df = pd.concat(test_dfs)\n",
        "\n",
        "    return output_df"
      ],
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qy8EnNQdOwUf"
      },
      "source": [
        "##move closer truth SJC"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sXN7rNZK1Ufv"
      },
      "source": [
        "def create_dataset_truth_train(input_df):\n",
        "    train_SJC_list = [\"2021-04-22-US-SJC-1\", \"2021-04-28-US-SJC-1\", \"2021-04-29-US-SJC-2\"]\n",
        "    #train_SJCs = []\n",
        "    #for SJC in train_SJC_list:\n",
        "       # SJC_df = input_df[input_df[\"collectionName\"] == SJC]\n",
        "       # train_SJCs.append(SJC_df)\n",
        "    #train_SJC = pd.concat(train_SJCs)\n",
        "    output_df = input_df.copy()\n",
        "    lat_list = []\n",
        "    lng_list = []\n",
        "    for collection in train_SJC_list:\n",
        "        collection_df = train_base[train_base[\"collectionName\"] == collection]\n",
        "        for phone in collection_df[\"phone\"].unique():\n",
        "            phone_df = collection_df[collection_df[\"phone\"] == phone]\n",
        "            phone_df[\"t_latDeg_pro\"] = phone_df[\"t_latDeg\"].shift(-1)\n",
        "            phone_df[\"t_lngDeg_pro\"] = phone_df[\"t_lngDeg\"].shift(-1)\n",
        "            for lat, lng, lat_pre, lng_pre in zip(\n",
        "                phone_df[\"t_latDeg\"].to_numpy(),\n",
        "                phone_df[\"t_lngDeg\"].to_numpy(),\n",
        "                phone_df[\"t_latDeg_pro\"].to_numpy(),\n",
        "                phone_df[\"t_lngDeg_pro\"].to_numpy()\n",
        "            ):\n",
        "                lat_list.append(lat)\n",
        "                lng_list.append(lng)\n",
        "                lat_mean = (lat + lat_pre)/2\n",
        "                lng_mean = (lng + lng_pre)/2\n",
        "                lat_list.append(lat_mean)\n",
        "                lng_list.append(lng_mean)\n",
        "\n",
        "    points_list = []\n",
        "    for lat, lng in zip(\n",
        "        lat_list,\n",
        "        lng_list\n",
        "    ):\n",
        "        points_list.append([lat, lng])\n",
        "\n",
        "    nearest_points_list = []\n",
        "    for lat, lng in zip(\n",
        "        output_df[\"latDeg\"].to_numpy(),\n",
        "        output_df[\"lngDeg\"].to_numpy()\n",
        "    ):\n",
        "        nearest_points_list.append(nearest_point(lat, lng, points_list))\n",
        "\n",
        "    nearest_points_df = pd.DataFrame(nearest_points_list)\n",
        "    output_df[\"latDeg_from_gt\"] = nearest_points_df[0].values\n",
        "    output_df[\"lngDeg_from_gt\"] = nearest_points_df[1].values\n",
        "    \n",
        "    lat_gt_pre_list = []\n",
        "    lng_gt_pre_list = []\n",
        "    for collection in output_df[\"collectionName\"].unique():\n",
        "        collection_df = output_df[output_df[\"collectionName\"] == collection]\n",
        "        for phone in collection_df[\"phoneName\"].unique():\n",
        "            phone_df = collection_df[collection_df[\"phoneName\"] == phone]\n",
        "            phone_df[\"latDeg_from_gt_pre\"] = phone_df[\"latDeg_from_gt\"].shift(-1)\n",
        "            phone_df[\"lngDeg_from_gt_pre\"] = phone_df[\"lngDeg_from_gt\"].shift(-1)\n",
        "            for lat_gt_pre, lng_gt_pre in zip(\n",
        "                phone_df[\"latDeg_from_gt_pre\"].to_numpy(),\n",
        "                phone_df[\"lngDeg_from_gt_pre\"].to_numpy(),\n",
        "            ):\n",
        "                lat_gt_pre_list.append(lat_gt_pre)\n",
        "                lng_gt_pre_list.append(lng_gt_pre)    \n",
        "        \n",
        "        output_df[\"latDeg_from_gt_pre\"] = lat_gt_pre_list\n",
        "        output_df[\"lngDeg_from_gt_pre\"] = lng_gt_pre_list\n",
        "\n",
        "    output_df[\"meter\"] = output_df.apply(\n",
        "        lambda r:calc_haversine(\n",
        "            r.latDeg, r.lngDeg, r.latDeg_from_gt, r.lngDeg_from_gt\n",
        "        ),\n",
        "        axis=1\n",
        "    )\n",
        "    return output_df\n"
      ],
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RodqE4LAbBnU"
      },
      "source": [
        "def check_meter_from_truth(input_df):\n",
        "    output_df = input_df.copy()\n",
        "    lat_list = []\n",
        "    lng_list = []\n",
        "    for lat, lng, lat_gt, lng_gt, meter in zip(\n",
        "        output_df[\"latDeg\"].to_numpy(),\n",
        "        output_df[\"lngDeg\"].to_numpy(),\n",
        "        output_df[\"latDeg_from_gt\"].to_numpy(),\n",
        "        output_df[\"lngDeg_from_gt\"].to_numpy(),\n",
        "        output_df[\"meter\"].to_numpy(),\n",
        "    ):\n",
        "        if meter > 30:\n",
        "            lat = lat\n",
        "            lng = lng\n",
        "        elif meter > 10:\n",
        "            lat = ((((lat + lat_gt)/2 + lat_gt)/2 + lat_gt)/2 + lat_gt)/2\n",
        "            lng = ((((lng + lng_gt)/2 + lng_gt)/2 + lng_gt)/2 + lng_gt)/2\n",
        "        elif meter > 7.5:\n",
        "            lat = (((lat + lat_gt)/2 + lat_gt)/2 + lat_gt)/2\n",
        "            lng = (((lng + lng_gt)/2 + lng_gt)/2 + lng_gt)/2\n",
        "        elif meter > 5:\n",
        "            lat = ((lat + lat_gt)/2 + lat_gt)/2\n",
        "            lng = ((lng + lng_gt)/2 + lng_gt)/2\n",
        "        elif meter > 2.5:\n",
        "            lat = (lat + lat_gt)/2\n",
        "            lng = (lng + lng_gt)/2\n",
        "\n",
        "        lat_list.append(lat)\n",
        "        lng_list.append(lng)\n",
        "\n",
        "\n",
        "    output_df.iloc[:, 2] = lat_list\n",
        "    output_df.iloc[:, 3] = lng_list\n",
        "    return output_df"
      ],
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-B8-f_ntx2pi"
      },
      "source": [
        "def move_closer_truth_train(input_df):\n",
        "    train_SJC_list = [\"2021-04-22-US-SJC-1\", \"2021-04-28-US-SJC-1\", \"2021-04-29-US-SJC-2\"]\n",
        "    train_dfs = []\n",
        "    for collection in input_df[\"collectionName\"].unique():\n",
        "        if collection in train_SJC_list:\n",
        "            phones_dfs = []\n",
        "            collection_df = input_df[input_df[\"collectionName\"] == collection]\n",
        "            for phone in collection_df[\"phone\"].unique():\n",
        "                phone_df = collection_df[collection_df[\"phone\"] == phone]\n",
        "                phone_df = create_dataset_truth_train(phone_df)\n",
        "                phone_df = check_meter_from_truth(phone_df)\n",
        "                phones_dfs.append(phone_df)\n",
        "            collection_df = pd.concat(phones_dfs)\n",
        "            train_dfs.append(collection_df)\n",
        "        else:\n",
        "            train_dfs.append(input_df[input_df[\"collectionName\"] == collection])\n",
        "    output_df = pd.concat(train_dfs)\n",
        "\n",
        "    return output_df"
      ],
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2LHOYs4fkyel"
      },
      "source": [
        "def move_closer_truth(input_df):\n",
        "    test_SJC_list = [\"2021-04-22-US-SJC-2\", \"2021-04-29-US-SJC-3\"]\n",
        "    test_dfs = []\n",
        "    for collection in input_df[\"collectionName\"].unique():\n",
        "        if collection in test_SJC_list:\n",
        "            phones_dfs = []\n",
        "            collection_df = input_df[input_df[\"collectionName\"] == collection]\n",
        "            for phone in collection_df[\"phone\"].unique():\n",
        "                phone_df = collection_df[collection_df[\"phone\"] == phone]\n",
        "                phone_df = create_dataset_truth_train(phone_df)\n",
        "                phone_df = check_meter_from_truth(phone_df)\n",
        "                phones_dfs.append(phone_df)\n",
        "            collection_df = pd.concat(phones_dfs)\n",
        "            test_dfs.append(collection_df)\n",
        "        else:\n",
        "            test_dfs.append(input_df[input_df[\"collectionName\"] == collection])\n",
        "    output_df = pd.concat(test_dfs)\n",
        "\n",
        "    return output_df"
      ],
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9o_Sn68eOwSK"
      },
      "source": [
        "#cheke CV"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cvl-zr9bhiYp"
      },
      "source": [
        "def check_score(input_df: pd.DataFrame) -> pd.DataFrame:\n",
        "    output_df = input_df.copy()\n",
        "    \n",
        "    output_df['meter'] = input_df.apply(\n",
        "        lambda r: calc_haversine(\n",
        "            r.latDeg, r.lngDeg, r.t_latDeg, r.t_lngDeg\n",
        "        ),\n",
        "        axis=1\n",
        "    )\n",
        "\n",
        "    meter_score = output_df['meter'].mean()\n",
        "    print(f'error meter: {meter_score}')\n",
        "\n",
        "    scores = []\n",
        "    for phone in output_df['phone'].unique():\n",
        "        _index = output_df['phone']==phone\n",
        "        p_50 = np.percentile(output_df.loc[_index, 'meter'], 50)\n",
        "        p_95 = np.percentile(output_df.loc[_index, 'meter'], 95)\n",
        "        scores.append(p_50)\n",
        "        scores.append(p_95)\n",
        "\n",
        "    score = sum(scores) / len(scores)\n",
        "    print(f'score: {score}')\n",
        "    \n",
        "    return output_df"
      ],
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RMmU1hfWb7un"
      },
      "source": [
        "#make triangle 1\n",
        "CV1 = make_triangle(train_base)\n",
        "for i in range(300):\n",
        "    CV1 = make_triangle(CV1)\n",
        "print('<<<triangle_1>>>')\n",
        "CV1 = check_score(CV1)\n",
        "print('--------------------')\n",
        "\n",
        "outlier\n",
        "CV2 = outlier_train(CV1)\n",
        "print('<<<outlier>>>')\n",
        "CV2 = check_score(CV2)\n",
        "print('--------------------')\n",
        "\n",
        "#make triangle 2\n",
        "CV3 = make_triangle(CV1)\n",
        "for i in range(300):\n",
        "    CV3 = make_triangle(CV3)\n",
        "print('<<<triangle_2>>>')\n",
        "CV3 = check_score(CV3)\n",
        "print('--------------------')\n",
        "\n",
        "#phonse mean\n",
        "CV4 = mean_prediction_train(CV1)\n",
        "print('<<<phones_mean>>>')\n",
        "CV4 = check_score(CV4)\n",
        "print('--------------------')\n",
        "\n",
        "#make triangle 3\n",
        "CV5 = make_triangle(CV4)\n",
        "for i in range(300):\n",
        "    CV5 = make_triangle(CV5)\n",
        "print('<<<triangle_3>>>')\n",
        "CV5 = check_score(CV5)\n",
        "print('--------------------')\n",
        "\n",
        "#remove device\n",
        "CV6 = remove_device(CV5)\n",
        "print('<<<remove_device>>>')\n",
        "CV6 = check_score(CV6)\n",
        "print('--------------------')\n",
        "\n",
        "#make triangle 4\n",
        "CV7 = make_triangle(CV6)\n",
        "for i in range(300):\n",
        "    CV7 = make_triangle(CV7)\n",
        "print('<<<triangle_4>>>')\n",
        "CV7 = check_score(CV7)\n",
        "print('--------------------')\n",
        "\n",
        "#position shift\n",
        "CV8 = position_shift_train(CV7)\n",
        "print('<<<position_shift>>>')\n",
        "CV8 = check_score(CV8)\n",
        "print('--------------------')\n",
        "\n",
        "#make triangle 5\n",
        "CV9 = make_triangle(CV8)\n",
        "for i in range(300):\n",
        "    CV9 = make_triangle(CV9)\n",
        "print('<<<triangle_5>>>')\n",
        "CV9 = check_score(CV9)\n",
        "print('--------------------')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "0439c0b364f9464cab02ae9491ef582a",
            "d594c5d2c492424894f80898bd6df2aa",
            "52965c1753c14e98b365788af7e0fa6a",
            "bb5c485d2ca94021bed3cd62747424ed",
            "d32d7f326c18456c96fe5bcc8435c280",
            "12e8b6d1f0254d50b82b17514f1ed468",
            "83a50f7026394224936d20f5fdced67f",
            "d3769aefdfd042c2988d1cb4685e6218"
          ]
        },
        "id": "ixAVyW3bs8Lf",
        "outputId": "e35407c4-fcaf-4258-bf98-2bfdbaea66de"
      },
      "source": [
        "#make triangle 1\n",
        "CV1 = make_triangle(train_base)\n",
        "for i in range(100):\n",
        "    CV1 = make_triangle(CV1)\n",
        "print('<<<triangle_1>>>')\n",
        "CV1 = check_score(CV1)\n",
        "print('--------------------')\n",
        "\n",
        "outlier\n",
        "CV2 = outlier_train(CV1)\n",
        "print('<<<outlier>>>')\n",
        "CV2 = check_score(CV2)\n",
        "print('--------------------')\n",
        "\n",
        "#make triangle 2\n",
        "CV3 = make_triangle(CV1)\n",
        "for i in range(100):\n",
        "    CV3 = make_triangle(CV3)\n",
        "print('<<<triangle_2>>>')\n",
        "CV3 = check_score(CV3)\n",
        "print('--------------------')\n",
        "\n",
        "#phonse mean\n",
        "CV4 = mean_prediction_train(CV1)\n",
        "print('<<<phones_mean>>>')\n",
        "CV4 = check_score(CV4)\n",
        "print('--------------------')\n",
        "\n",
        "#make triangle 3\n",
        "CV5 = make_triangle(CV4)\n",
        "for i in range(100):\n",
        "    CV5 = make_triangle(CV5)\n",
        "print('<<<triangle_3>>>')\n",
        "CV5 = check_score(CV5)\n",
        "print('--------------------')\n",
        "\n",
        "#remove device\n",
        "CV6 = remove_device(CV5)\n",
        "print('<<<remove_device>>>')\n",
        "CV6 = check_score(CV6)\n",
        "print('--------------------')\n",
        "\n",
        "#make triangle 4\n",
        "CV7 = make_triangle(CV6)\n",
        "for i in range(100):\n",
        "    CV7 = make_triangle(CV7)\n",
        "print('<<<triangle_4>>>')\n",
        "CV7 = check_score(CV7)\n",
        "print('--------------------')\n",
        "\n",
        "#position shift\n",
        "CV8 = position_shift_train(CV7)\n",
        "print('<<<position_shift>>>')\n",
        "CV8 = check_score(CV8)\n",
        "print('--------------------')\n",
        "\n",
        "#make triangle 5\n",
        "CV9 = make_triangle(CV8)\n",
        "for i in range(100):\n",
        "    CV9 = make_triangle(CV9)\n",
        "print('<<<triangle_5>>>')\n",
        "CV9 = check_score(CV9)\n",
        "print('--------------------')\n"
      ],
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:37: RuntimeWarning:\n",
            "\n",
            "invalid value encountered in double_scalars\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:37: RuntimeWarning:\n",
            "\n",
            "invalid value encountered in arccos\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "<<<triangle_1>>>\n",
            "< from truth >\n",
            "error meter: 3.3579582394393928\n",
            "score: 4.753446293953488\n",
            "--------------------\n",
            "<<<outlier>>>\n",
            "< from truth >\n",
            "error meter: 3.357550751702286\n",
            "score: 4.753387012675808\n",
            "--------------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:37: RuntimeWarning:\n",
            "\n",
            "invalid value encountered in double_scalars\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "<<<triangle_2>>>\n",
            "< from truth >\n",
            "error meter: 3.345099090946541\n",
            "score: 4.74999834268959\n",
            "--------------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "0439c0b364f9464cab02ae9491ef582a",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=73.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "<<<phones_mean>>>\n",
            "< from truth >\n",
            "error meter: 2.9007008123380005\n",
            "score: 3.981980123726002\n",
            "--------------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:37: RuntimeWarning:\n",
            "\n",
            "invalid value encountered in double_scalars\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "<<<triangle_3>>>\n",
            "< from truth >\n",
            "error meter: 2.8872760220798033\n",
            "score: 3.9663206629532684\n",
            "--------------------\n",
            "<<<remove_device>>>\n",
            "< from truth >\n",
            "error meter: 2.8016813590135117\n",
            "score: 3.8280556672332895\n",
            "--------------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:37: RuntimeWarning:\n",
            "\n",
            "invalid value encountered in arccos\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "<<<triangle_4>>>\n",
            "< from truth >\n",
            "error meter: 2.798629756223295\n",
            "score: 3.8188926375636387\n",
            "--------------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-07-25 15:39:23,450]\u001b[0m A new study created in memory with name: no-name-394f12c9-638e-496d-9279-705cb5c51c49\u001b[0m\n",
            "\u001b[32m[I 2021-07-25 15:39:29,244]\u001b[0m Trial 0 finished with value: 5.3557137552978205 and parameters: {'a': -0.20221613407575423}. Best is trial 0 with value: 5.3557137552978205.\u001b[0m\n",
            "\u001b[32m[I 2021-07-25 15:39:35,204]\u001b[0m Trial 1 finished with value: 5.191875339955317 and parameters: {'a': 0.5071061413177271}. Best is trial 1 with value: 5.191875339955317.\u001b[0m\n",
            "\u001b[32m[I 2021-07-25 15:39:41,064]\u001b[0m Trial 2 finished with value: 5.198066276324267 and parameters: {'a': 0.41356780482437405}. Best is trial 1 with value: 5.191875339955317.\u001b[0m\n",
            "\u001b[32m[I 2021-07-25 15:39:46,904]\u001b[0m Trial 3 finished with value: 5.298337597801392 and parameters: {'a': -0.031088325597563138}. Best is trial 1 with value: 5.191875339955317.\u001b[0m\n",
            "\u001b[32m[I 2021-07-25 15:39:52,993]\u001b[0m Trial 4 finished with value: 5.446121602492475 and parameters: {'a': -0.42582865602333864}. Best is trial 1 with value: 5.191875339955317.\u001b[0m\n",
            "\u001b[32m[I 2021-07-25 15:39:59,161]\u001b[0m Trial 5 finished with value: 5.5941872415383855 and parameters: {'a': -0.7188989653121389}. Best is trial 1 with value: 5.191875339955317.\u001b[0m\n",
            "\u001b[32m[I 2021-07-25 15:40:05,178]\u001b[0m Trial 6 finished with value: 5.283421045903776 and parameters: {'a': 0.015743076223700747}. Best is trial 1 with value: 5.191875339955317.\u001b[0m\n",
            "\u001b[32m[I 2021-07-25 15:40:11,349]\u001b[0m Trial 7 finished with value: 5.2063626469683335 and parameters: {'a': 0.3493469330216725}. Best is trial 1 with value: 5.191875339955317.\u001b[0m\n",
            "\u001b[32m[I 2021-07-25 15:40:17,151]\u001b[0m Trial 8 finished with value: 5.5195949936388935 and parameters: {'a': -0.5782942539778746}. Best is trial 1 with value: 5.191875339955317.\u001b[0m\n",
            "\u001b[32m[I 2021-07-25 15:40:23,033]\u001b[0m Trial 9 finished with value: 5.201787222951117 and parameters: {'a': 0.3788677024755005}. Best is trial 1 with value: 5.191875339955317.\u001b[0m\n",
            "\u001b[32m[I 2021-07-25 15:40:28,792]\u001b[0m Trial 10 finished with value: 5.209896634509924 and parameters: {'a': 0.9611726459045492}. Best is trial 1 with value: 5.191875339955317.\u001b[0m\n",
            "\u001b[32m[I 2021-07-25 15:40:34,733]\u001b[0m Trial 11 finished with value: 5.200642933276237 and parameters: {'a': 0.8821309084020428}. Best is trial 1 with value: 5.191875339955317.\u001b[0m\n",
            "\u001b[32m[I 2021-07-25 15:40:40,352]\u001b[0m Trial 12 finished with value: 5.190983447691926 and parameters: {'a': 0.5375342075801758}. Best is trial 12 with value: 5.190983447691926.\u001b[0m\n",
            "\u001b[32m[I 2021-07-25 15:40:46,201]\u001b[0m Trial 13 finished with value: 5.1885983547245225 and parameters: {'a': 0.6888814741938439}. Best is trial 13 with value: 5.1885983547245225.\u001b[0m\n",
            "\u001b[32m[I 2021-07-25 15:40:52,041]\u001b[0m Trial 14 finished with value: 5.192841220493749 and parameters: {'a': 0.7425730930208344}. Best is trial 13 with value: 5.1885983547245225.\u001b[0m\n",
            "\u001b[32m[I 2021-07-25 15:40:57,922]\u001b[0m Trial 15 finished with value: 5.188728116944081 and parameters: {'a': 0.6904666454356247}. Best is trial 13 with value: 5.1885983547245225.\u001b[0m\n",
            "\u001b[32m[I 2021-07-25 15:41:04,046]\u001b[0m Trial 16 finished with value: 5.189297071161077 and parameters: {'a': 0.7023043048599131}. Best is trial 13 with value: 5.1885983547245225.\u001b[0m\n",
            "\u001b[32m[I 2021-07-25 15:41:10,095]\u001b[0m Trial 17 finished with value: 5.250617308531621 and parameters: {'a': 0.13029617512278846}. Best is trial 13 with value: 5.1885983547245225.\u001b[0m\n",
            "\u001b[32m[I 2021-07-25 15:41:16,149]\u001b[0m Trial 18 finished with value: 5.212523211461123 and parameters: {'a': 0.9840436364759274}. Best is trial 13 with value: 5.1885983547245225.\u001b[0m\n",
            "\u001b[32m[I 2021-07-25 15:41:22,024]\u001b[0m Trial 19 finished with value: 5.1883436473399485 and parameters: {'a': 0.6846913280385831}. Best is trial 19 with value: 5.1883436473399485.\u001b[0m\n",
            "\u001b[32m[I 2021-07-25 15:41:27,781]\u001b[0m Trial 20 finished with value: 5.2367463824767135 and parameters: {'a': 0.19359781344677818}. Best is trial 19 with value: 5.1883436473399485.\u001b[0m\n",
            "\u001b[32m[I 2021-07-25 15:41:33,541]\u001b[0m Trial 21 finished with value: 5.18994404350377 and parameters: {'a': 0.7097160716392087}. Best is trial 19 with value: 5.1883436473399485.\u001b[0m\n",
            "\u001b[32m[I 2021-07-25 15:41:39,310]\u001b[0m Trial 22 finished with value: 5.195925422246299 and parameters: {'a': 0.8007246623212774}. Best is trial 19 with value: 5.1883436473399485.\u001b[0m\n",
            "\u001b[32m[I 2021-07-25 15:41:44,966]\u001b[0m Trial 23 finished with value: 5.189699670407723 and parameters: {'a': 0.5999687906853174}. Best is trial 19 with value: 5.1883436473399485.\u001b[0m\n",
            "\u001b[32m[I 2021-07-25 15:41:50,840]\u001b[0m Trial 24 finished with value: 5.214127837744016 and parameters: {'a': 0.9965853924335772}. Best is trial 19 with value: 5.1883436473399485.\u001b[0m\n",
            "\u001b[32m[I 2021-07-25 15:41:56,651]\u001b[0m Trial 25 finished with value: 5.738448329783024 and parameters: {'a': -0.9740135484875646}. Best is trial 19 with value: 5.1883436473399485.\u001b[0m\n",
            "\u001b[32m[I 2021-07-25 15:42:02,243]\u001b[0m Trial 26 finished with value: 5.21838994030592 and parameters: {'a': 0.2817554324282103}. Best is trial 19 with value: 5.1883436473399485.\u001b[0m\n",
            "\u001b[32m[I 2021-07-25 15:42:08,276]\u001b[0m Trial 27 finished with value: 5.190939756659662 and parameters: {'a': 0.5606981364207843}. Best is trial 19 with value: 5.1883436473399485.\u001b[0m\n",
            "\u001b[32m[I 2021-07-25 15:42:14,275]\u001b[0m Trial 28 finished with value: 5.198952589610528 and parameters: {'a': 0.8629326595529399}. Best is trial 19 with value: 5.1883436473399485.\u001b[0m\n",
            "\u001b[32m[I 2021-07-25 15:42:20,331]\u001b[0m Trial 29 finished with value: 5.355517386328881 and parameters: {'a': -0.20176020770922903}. Best is trial 19 with value: 5.1883436473399485.\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "<<<position_shift>>>\n",
            "< from truth >\n",
            "error meter: 2.7591453852236514\n",
            "score: 3.7686592938431867\n",
            "--------------------\n",
            "<<<triangle_5>>>\n",
            "< from truth >\n",
            "error meter: 2.752150928938555\n",
            "score: 3.7514450182440835\n",
            "--------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G3qCk_JazSRc",
        "outputId": "83e02989-b52e-48f4-f82d-5a360e890f6d"
      },
      "source": [
        "#guass filter\n",
        "CV10 = gauss_filter(CV9)\n",
        "print('<<<guass_filter>>>')\n",
        "CV10 = check_score(CV10)\n",
        "print('--------------------')"
      ],
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<<<guass_filter>>>\n",
            "< from truth >\n",
            "error meter: 2.6036190839626507\n",
            "score: 3.6035377929735564\n",
            "--------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XUlKmA8tI2x4",
        "outputId": "ba90aa97-c108-449f-df3d-efcf11996f7f"
      },
      "source": [
        "CV11 = move_closer_truth_train(CV10)\n",
        "CV11 = check_score(CV11)"
      ],
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:15: SettingWithCopyWarning:\n",
            "\n",
            "\n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:16: SettingWithCopyWarning:\n",
            "\n",
            "\n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "< from truth >\n",
            "error meter: 2.484862036936544\n",
            "score: 3.391664375431734\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6UWt5P7zQwxP"
      },
      "source": [
        "#submission"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 979,
          "referenced_widgets": [
            "01bf756b3a74465f929b08a2efc96cb3",
            "17974162bf38469f9628811e8e27414e",
            "f5728f1783324a3b9f11d891596842f6",
            "f01432b1a746489e966dadeae5743798",
            "6141c6e56b704b058312167647d41148",
            "2a50a1ffe6c34aa190eebd7de6aa4075",
            "41e1d0df8a3e4916b48fba5065874b51",
            "b70f60875963407db81116ad407da7e7"
          ]
        },
        "id": "U-qhbrlXOXA4",
        "outputId": "bf97216e-b07b-4f10-bf31-131386a669b0"
      },
      "source": [
        "#make triangle 1\n",
        "sub1 = make_triangle(test_base)\n",
        "for i in range(300):\n",
        "    sub1 = make_triangle(sub1)\n",
        "print('<<<triangle_1>>>')\n",
        "\n",
        "#outlier\n",
        "sub2 = outlier(sub1)\n",
        "print('<<<outlier>>>')\n",
        "\n",
        "#make triangle 2\n",
        "sub3 = make_triangle(sub2)\n",
        "for i in range(300):\n",
        "    sub3 = make_triangle(sub3)\n",
        "print('<<<triangle_2>>>')\n",
        "\n",
        "#phonse mean\n",
        "sub4 = mean_prediction(sub3)\n",
        "print('<<<phones_mean>>>')\n",
        "\n",
        "#make triangle 3\n",
        "sub5 = make_triangle(sub4)\n",
        "for i in range(300):\n",
        "    sub5 = make_triangle(sub5)\n",
        "print('<<<triangle_3>>>')\n",
        "\n",
        "#remove device\n",
        "sub6 = remove_device(sub5)\n",
        "print('<<<remove_device>>>')\n",
        "\n",
        "#make triangle 4\n",
        "sub7 = make_triangle(sub6)\n",
        "for i in range(300):\n",
        "    sub7 = make_triangle(sub7)\n",
        "print('<<<triangle_4>>>')\n",
        "\n",
        "#position shift\n",
        "sub8 = position_shift(sub7)\n",
        "print('<<<position_shift>>>')\n",
        "\n",
        "#make triangle 5\n",
        "sub9 = make_triangle(sub8)\n",
        "for i in range(300):\n",
        "    sub9 = make_triangle(sub9)\n",
        "print('<<<triangle_5>>>')\n",
        "\n",
        "#guass filter\n",
        "sub10 = gauss_filter(sub9)\n",
        "print('<<<guass_filter>>>')\n",
        "\n",
        "#move closer truth\n",
        "sub11 = move_closer_truth(sub10)\n",
        "print('<<<move_closer_truth>>>')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:37: RuntimeWarning:\n",
            "\n",
            "invalid value encountered in double_scalars\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "<<<triangle_1>>>\n",
            "<<<outlier>>>\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:37: RuntimeWarning:\n",
            "\n",
            "invalid value encountered in double_scalars\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:37: RuntimeWarning:\n",
            "\n",
            "invalid value encountered in arccos\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "<<<triangle_2>>>\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "01bf756b3a74465f929b08a2efc96cb3",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=48.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "<<<phones_mean>>>\n",
            "<<<triangle_3>>>\n",
            "<<<remove_device>>>\n",
            "<<<triangle_4>>>\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-07-25 17:07:08,503]\u001b[0m A new study created in memory with name: no-name-30005a76-7f03-429b-8dc0-511dc1a6e372\u001b[0m\n",
            "\u001b[32m[I 2021-07-25 17:07:14,685]\u001b[0m Trial 0 finished with value: 5.300085686944338 and parameters: {'a': -0.03762564054280304}. Best is trial 0 with value: 5.300085686944338.\u001b[0m\n",
            "\u001b[32m[I 2021-07-25 17:07:20,845]\u001b[0m Trial 1 finished with value: 5.304001296697287 and parameters: {'a': -0.054471198502757945}. Best is trial 0 with value: 5.300085686944338.\u001b[0m\n",
            "\u001b[32m[I 2021-07-25 17:07:26,967]\u001b[0m Trial 2 finished with value: 5.338063281623755 and parameters: {'a': -0.15715175302736362}. Best is trial 0 with value: 5.300085686944338.\u001b[0m\n",
            "\u001b[32m[I 2021-07-25 17:07:33,081]\u001b[0m Trial 3 finished with value: 5.208251534024152 and parameters: {'a': 0.33933517017453996}. Best is trial 3 with value: 5.208251534024152.\u001b[0m\n",
            "\u001b[32m[I 2021-07-25 17:07:39,304]\u001b[0m Trial 4 finished with value: 5.194495812482733 and parameters: {'a': 0.45881993215629313}. Best is trial 4 with value: 5.194495812482733.\u001b[0m\n",
            "\u001b[32m[I 2021-07-25 17:07:45,467]\u001b[0m Trial 5 finished with value: 5.368498968162815 and parameters: {'a': -0.23668411685385538}. Best is trial 4 with value: 5.194495812482733.\u001b[0m\n",
            "\u001b[32m[I 2021-07-25 17:07:51,505]\u001b[0m Trial 6 finished with value: 5.655155450444908 and parameters: {'a': -0.8313280950476065}. Best is trial 4 with value: 5.194495812482733.\u001b[0m\n",
            "\u001b[32m[I 2021-07-25 17:07:57,759]\u001b[0m Trial 7 finished with value: 5.361819285856284 and parameters: {'a': -0.21890451940431932}. Best is trial 4 with value: 5.194495812482733.\u001b[0m\n",
            "\u001b[32m[I 2021-07-25 17:08:03,969]\u001b[0m Trial 8 finished with value: 5.31024468917321 and parameters: {'a': -0.07679381796332652}. Best is trial 4 with value: 5.194495812482733.\u001b[0m\n",
            "\u001b[32m[I 2021-07-25 17:08:10,264]\u001b[0m Trial 9 finished with value: 5.634942635274311 and parameters: {'a': -0.7951106286713936}. Best is trial 4 with value: 5.194495812482733.\u001b[0m\n",
            "\u001b[32m[I 2021-07-25 17:08:16,474]\u001b[0m Trial 10 finished with value: 5.213632893452597 and parameters: {'a': 0.9927784999832873}. Best is trial 4 with value: 5.194495812482733.\u001b[0m\n",
            "\u001b[32m[I 2021-07-25 17:08:22,775]\u001b[0m Trial 11 finished with value: 5.187450989537174 and parameters: {'a': 0.6467215239187517}. Best is trial 11 with value: 5.187450989537174.\u001b[0m\n",
            "\u001b[32m[I 2021-07-25 17:08:29,108]\u001b[0m Trial 12 finished with value: 5.1906811542251745 and parameters: {'a': 0.7164058895703199}. Best is trial 11 with value: 5.187450989537174.\u001b[0m\n",
            "\u001b[32m[I 2021-07-25 17:08:35,259]\u001b[0m Trial 13 finished with value: 5.212118266425629 and parameters: {'a': 0.9813344375894895}. Best is trial 11 with value: 5.187450989537174.\u001b[0m\n",
            "\u001b[32m[I 2021-07-25 17:08:41,544]\u001b[0m Trial 14 finished with value: 5.1877860319557385 and parameters: {'a': 0.637639725667356}. Best is trial 11 with value: 5.187450989537174.\u001b[0m\n",
            "\u001b[32m[I 2021-07-25 17:08:47,725]\u001b[0m Trial 15 finished with value: 5.20298433527443 and parameters: {'a': 0.37061576437991994}. Best is trial 11 with value: 5.187450989537174.\u001b[0m\n",
            "\u001b[32m[I 2021-07-25 17:08:54,073]\u001b[0m Trial 16 finished with value: 5.189966148478331 and parameters: {'a': 0.7099489951560268}. Best is trial 11 with value: 5.187450989537174.\u001b[0m\n",
            "\u001b[32m[I 2021-07-25 17:09:00,451]\u001b[0m Trial 17 finished with value: 5.189121438668993 and parameters: {'a': 0.6964993544443951}. Best is trial 11 with value: 5.187450989537174.\u001b[0m\n",
            "\u001b[32m[I 2021-07-25 17:09:06,631]\u001b[0m Trial 18 finished with value: 5.241183469652691 and parameters: {'a': 0.1738177696293301}. Best is trial 11 with value: 5.187450989537174.\u001b[0m\n",
            "\u001b[32m[I 2021-07-25 17:09:12,858]\u001b[0m Trial 19 finished with value: 5.4816346482254215 and parameters: {'a': -0.50261982423983}. Best is trial 11 with value: 5.187450989537174.\u001b[0m\n",
            "\u001b[32m[I 2021-07-25 17:09:19,027]\u001b[0m Trial 20 finished with value: 5.189917996793374 and parameters: {'a': 0.5907696769232046}. Best is trial 11 with value: 5.187450989537174.\u001b[0m\n",
            "\u001b[32m[I 2021-07-25 17:09:25,344]\u001b[0m Trial 21 finished with value: 5.198737125375977 and parameters: {'a': 0.8526355600884998}. Best is trial 11 with value: 5.187450989537174.\u001b[0m\n",
            "\u001b[32m[I 2021-07-25 17:09:31,504]\u001b[0m Trial 22 finished with value: 5.235028503685225 and parameters: {'a': 0.20054369166248417}. Best is trial 11 with value: 5.187450989537174.\u001b[0m\n",
            "\u001b[32m[I 2021-07-25 17:09:37,783]\u001b[0m Trial 23 finished with value: 5.18997474050991 and parameters: {'a': 0.585870187369862}. Best is trial 11 with value: 5.187450989537174.\u001b[0m\n",
            "\u001b[32m[I 2021-07-25 17:09:44,032]\u001b[0m Trial 24 finished with value: 5.196823157558712 and parameters: {'a': 0.8173298940181927}. Best is trial 11 with value: 5.187450989537174.\u001b[0m\n",
            "\u001b[32m[I 2021-07-25 17:09:50,408]\u001b[0m Trial 25 finished with value: 5.19181088737209 and parameters: {'a': 0.5279940623865842}. Best is trial 11 with value: 5.187450989537174.\u001b[0m\n",
            "\u001b[32m[I 2021-07-25 17:09:56,742]\u001b[0m Trial 26 finished with value: 5.2452509011395545 and parameters: {'a': 0.15237401785807914}. Best is trial 11 with value: 5.187450989537174.\u001b[0m\n",
            "\u001b[32m[I 2021-07-25 17:10:03,067]\u001b[0m Trial 27 finished with value: 5.202291109408311 and parameters: {'a': 0.8948882252189962}. Best is trial 11 with value: 5.187450989537174.\u001b[0m\n",
            "\u001b[32m[I 2021-07-25 17:10:09,301]\u001b[0m Trial 28 finished with value: 5.189052680438031 and parameters: {'a': 0.6947988759639253}. Best is trial 11 with value: 5.187450989537174.\u001b[0m\n",
            "\u001b[32m[I 2021-07-25 17:10:15,387]\u001b[0m Trial 29 finished with value: 5.212543025206394 and parameters: {'a': 0.31795023710406}. Best is trial 11 with value: 5.187450989537174.\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "<<<position_shift>>>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f7gndYYANy7_"
      },
      "source": [
        "sub11[sub.columns].to_csv(\"submission_61.csv\", index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uFq1lTdHS_au"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}